{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245fa5f6-554d-4099-9501-cd0fa8aae243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f87256-2a3c-4f76-98ab-cfddb68fb5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"fine_tuned_t5_updated/\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(save_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(save_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dc5cbb-1597-4d77-98fb-b233cdd23425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output:\n",
      " Mapping Value X Axis Tick 1 January 2 February 3 March 4 April 5 May 6 June 7 July 8 August 9 September 10 October 11 November 12 December\n"
     ]
    }
   ],
   "source": [
    "test_input_text = \"fill in the missing X Axis ticks: Mapping Value\\tX Axis Tick\\n1\\tJanuary\\n2\\t\\n3\\tMarch\\n4\\t\\n5\\tMay\\n6\\t\\n7\\tJuly\\n8\\t\\n9\\tSeptember\\n10\\t\\n11\\tNovember\\n12\\t\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_input_text, return_tensors = \"pt\").input_ids.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "outputs = model.generate(input_ids, max_length = 128)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "print(\"Generated Output:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b840c07b-ab57-4ec2-95f7-c30a64cb5ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output:\n",
      " Mapping Value X Axis Tick 1 Option 4 2 Option 8 3 Option 12 4 Option 16 5 Option 20 6 Option 24 7 Option 28 8 Option 32 9 Option 36\n"
     ]
    }
   ],
   "source": [
    "test_input_text = \"fill in the missing X Axis ticks:\\nMapping Value\\tX Axis Tick\\n1\\tOption 4\\n2\\t\\n3\\tOption 12\\n4\\t\\n5\\tOption 20\\n6\\t\\n7\\tOption 28\\n8\\t\\n9\\tOption 36\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_input_text, return_tensors = \"pt\").input_ids.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "outputs = model.generate(input_ids, max_length = 128)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "print(\"Generated Output:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ac804b-73df-4ad8-8823-6f23af2e2c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output:\n",
      " Mapping Value X Axis Tick 1 13-Dec-2021 2 18-Dec-2021 3 23-Dec-2021 4 28-Dec-2021 5 02-Jan-2022 6 06-Jan-2022 7 12-Jan-2022 8 18-Jan-2022\n"
     ]
    }
   ],
   "source": [
    "test_input_text = \"fill in the missing X Axis ticks:\\nMapping Value\\tX Axis Tick\\n1\\t13-Dec-2021\\n2\\t\\n3\\t23-Dec-2021\\n4\\t\\n5\\t02-Jan-2022\\n6\\t\\n7\\t12-Jan-2022\\n8\\t\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_input_text, return_tensors = \"pt\").input_ids.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "outputs = model.generate(input_ids, max_length = 128)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "print(\"Generated Output:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96e1106-f5a0-4815-82a3-aabab85edd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output:\n",
      " Mapping Value X Axis Tick 1 667 2 703 3 745 4 787 5 823 6 867 7 901 8 933\n"
     ]
    }
   ],
   "source": [
    "test_input_text = \"fill in the missing X Axis ticks:\\nMapping Value\\tX Axis Tick\\n1\\t667\\n2\\t\\n3\\t745\\n4\\t\\n5\\t823\\n6\\t\\n7\\t901\\n8\\t\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_input_text, return_tensors = \"pt\").input_ids.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "outputs = model.generate(input_ids, max_length = 128)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "print(\"Generated Output:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18bab8d-91c5-4322-9933-6dfb7844920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output:\n",
      " Mapping Value X Axis Tick 1 [-544, -519] 2 [-519, -494] 3 [-494, -469] 4 [-469, -444] 5 [-444, -419] 6 [-419, -394] 7 [-394, -369] 8 [-369, -344] 9 [-344, -319] 10 [-319, -294] 11 [-294, -269] 12 [-269, -294]\n"
     ]
    }
   ],
   "source": [
    "test_input_text = \"fill in the missing X Axis ticks:\\nMapping Value\\tX Axis Tick\\n1\\t[-544, -519]\\n2\\t\\n3\\t[-494, -469]\\n4\\t\\n5\\t[-444, -419]\\n6\\t\\n7\\t[-394, -369]\\n8\\t\\n9\\t[-344, -319]\\n10\\t\\n11\\t[-294, -269]\\n12\\t\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(test_input_text, return_tensors = \"pt\").input_ids.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "outputs = model.generate(input_ids, max_length = 128)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "print(\"Generated Output:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c776f-fe4f-4df7-892e-ad09e02ac9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
